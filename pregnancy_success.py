# -*- coding: utf-8 -*-
"""Pregnancy_Success.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1F0UGpEd0ut-UVCKBs8atgPrXgPn6r3cH
"""

#!/usr/bin/env python3
# main.py

import argparse
import os
import json
import datetime
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, StratifiedKFold
from sklearn.metrics import accuracy_score, roc_auc_score
from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler
from sklearn.base import BaseEstimator, TransformerMixin
# PyCaret imports
from pycaret.classification import setup, compare_models, finalize_model, save_model

# -----------------------------
# 1) 데이터 로더 & 클렌징 전략
# -----------------------------
def cleaning8(file_path: str) -> pd.DataFrame:
    """데이터 로딩 및 기본 클렌징 (cleaning8)"""
    df = pd.read_csv(file_path)
    drop_cols = [
        "ID",
        "임신 시도 또는 마지막 임신 경과 연수",
        "착상 전 유전 검사 사용 여부",
        "PGD 시술 여부",
        "PGS 시술 여부",
        "난자 해동 경과일",
        "배아 해동 경과일",
        "난자 채취 경과일",
        "불임 원인 - 여성 요인",
        "불임 원인 - 자궁경부 문제",
        "불임 원인 - 정자 면역학적 요인",
        "불임 원인 - 정자 형태",
        "정자 기증자 나이",
        "정자 출처",
    ]
    for col in drop_cols:
        if col in df.columns:
            df.drop(columns=col, inplace=True)
    print("[INFO] cleaning8 applied.")
    return df

# -----------------------------
# 2) 라벨링 전략
# -----------------------------
def labeling6(df: pd.DataFrame) -> pd.DataFrame:
    numeric_cols = [
        '총 시술 횟수', '클리닉 내 총 시술 횟수',
        'IVF 시술 횟수', 'DI 시술 횟수',
        '총 임신 횟수', 'IVF 임신 횟수', 'DI 임신 횟수',
        '총 출산 횟수', 'IVF 출산 횟수', 'DI 출산 횟수'
    ]
    mapping_dict = {'0회': 0, '1회': 1, '2회': 2, '3회': 3, '4회': 4, '5회': 5, '6회 이상': 6}
    for col in numeric_cols:
        if col in df.columns:
            df[col] = df[col].map(mapping_dict)
    if '배란 유도 유형' in df.columns:
        print('Before labeling6:', df['배란 유도 유형'].value_counts(dropna=False))
        df['배란 유도 유형'] = df['배란 유도 유형'].apply(lambda x: 0 if x == '기록되지 않은 시행' else 1)
        print('After labeling6:', df['배란 유도 유형'].value_counts(dropna=False))
        print("[INFO] labeling6 applied.")
    return df

# -----------------------------
# 3) 결측치 처리 전략
# -----------------------------
def basic4(df: pd.DataFrame, return_imputer: bool=False, imputer=None):
    for col in df.columns:
        if df[col].dtype == 'object':
            df[col].fillna('알 수 없음', inplace=True)
        else:
            df[col] = df[col].replace([np.inf, -np.inf], np.nan).fillna(-1)
    print("[INFO] basic4 applied.")
    if return_imputer:
        return df, None
    return df

# -----------------------------
# 4) 피처 엔지니어링 전략
# -----------------------------
class EnsembleScaler(BaseEstimator, TransformerMixin):
    def __init__(self, scalers=None, method='average'):
        self.scalers = scalers or [StandardScaler(), MinMaxScaler(), RobustScaler()]
        self.method = method
    def fit(self, X, y=None):
        self.fitted_ = [scaler.fit(X) for scaler in self.scalers]
        return self
    def transform(self, X):
        outs = [scaler.transform(X) for scaler in self.fitted_]
        if self.method == 'concat':
            return np.concatenate(outs, axis=1)
        return np.mean(outs, axis=0)

def feature_engineering9(
    df: pd.DataFrame,
    target: pd.Series=None,
    scaler: StandardScaler=None,
    return_scaler: bool=False,
    is_train: bool=True,
    target_enc_mapping: dict=None
):
    # One-hot encoding
    cat_ohe = [c for c in ['시술 시기 코드','난자 기증자 나이','정자 기증자 나이','시술 유형'] if c in df]
    df = pd.get_dummies(df, columns=cat_ohe, drop_first=True)
    # Target encoding
    cat_te = [c for c in ['시술 당시 나이','특정 시술 유형','배란 유도 유형','배아 생성 주요 이유','난자 출처','정자 출처'] if c in df]
    if is_train:
        if target is None: raise ValueError('target required in train mode')
        global_mean = target.mean(); target_enc_mapping={}
        smoothing, min_samp = 5, 5
        for col in cat_te:
            mapping = {}
            for category, group in df.groupby(col):
                cnt = len(group)
                cat_mean = target[group.index].mean()
                mapping[category] = global_mean if cnt < min_samp else (cat_mean*cnt + smoothing*global_mean)/(cnt + smoothing)
            mapping['_global_'] = global_mean
            target_enc_mapping[col] = mapping
            df[col] = df[col].map(mapping).fillna(global_mean)
    else:
        if target_enc_mapping is None: raise ValueError('mapping required in inference')
        for col in cat_te:
            mapping = target_enc_mapping[col]; gm = mapping.get('_global_', 0)
            df[col] = df[col].map(lambda x: mapping.get(x, gm))
    # Numeric processing & scaling
    num_cols = [c for c in [
        '기증자 정자와 혼합된 난자 수','미세주입 후 저장된 배아 수','해동된 배아 수','해동 난자 수',
        '저장된 신선 난자 수','난자 혼합 경과일','DI 시술 횟수','총 임신 횟수','IVF 임신 횟수','DI 임신 횟수',
        '총 출산 횟수','IVF 출산 횟수','DI 출산 횟수','총 시술 횟수','클리닉 내 총 시술 횟수','IVF 시술 횟수',
        '총 생성 배아 수','미세주입된 난자 수','미세주입에서 생성된 배아 수','이식된 배아 수',
        '미세주입 배아 이식 수','저장된 배아 수','수집된 신선 난자 수','혼합된 난자 수',
        '파트너 정자와 혼합된 난자 수','배아 이식 경과일'
    ] if c in df]
    for col in num_cols:
        df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0)
    if scaler is None:
        scaler = StandardScaler()
        df[num_cols] = scaler.fit_transform(df[num_cols])
    else:
        df[num_cols] = scaler.transform(df[num_cols])
    print("[INFO] feature_engineering9 applied.")
    return (df, scaler, target_enc_mapping) if return_scaler else (df, scaler, target_enc_mapping)

# Alias
fe9 = lambda df, target=None, scaler=None, return_scaler=False, is_train=True, target_enc_mapping=None: feature_engineering9(df, target, scaler, return_scaler, is_train, target_enc_mapping)

# -----------------------------
# 5) 샘플링 전략
# -----------------------------
def sampling_dummy(df: pd.DataFrame) -> (pd.DataFrame, object):
    print("[INFO] Dummy sampling applied (no resampling).")
    return df, None

# -----------------------------
# 6) 모델링 전략
# -----------------------------
def ensemble_split_majority2(
    train_df: pd.DataFrame,
    test_df: pd.DataFrame,
    model_path: str,
    feature_path: str,
    show_feature_importance: bool = False,
    n_splits: int = 3,
    **kwargs
) -> dict:
    """PyCaret 기반 앙상블 Split Majority 전략"""
    # train_df, test_df: target 컬럼 포함
    target_col = '임신 성공 여부'
    # 언더샘플링
    majority = train_df[train_df[target_col] == 0].sample(frac=1, random_state=42)
    minority = train_df[train_df[target_col] == 1]
    splits = np.array_split(majority.iloc[:len(minority) * n_splits], n_splits)

    individual_metrics = {}
    test_probas = []

    for i, split in enumerate(splits, start=1):
        subset = pd.concat([split, minority], ignore_index=True)
        print(f"[INFO] Split {i}: subset shape {subset.shape}")
        clf = setup(
            data=subset, target=target_col, session_id=42,
            use_gpu=False, fold_strategy='stratifiedkfold', fold=5, html=False
        )
        top_models = compare_models(sort='AUC', n_select=2)
        final_models = [finalize_model(m) for m in top_models]
        for idx, m in enumerate(final_models, 1):
            save_model(m, f"{model_path}_split{i}_model{idx}")
            print(f"[INFO] Saved model: {model_path}_split{i}_model{idx}")
        features = [c for c in subset.columns if c != target_col]
        # 테스트 정렬
        test_align = test_df.copy()
        for f in features:
            if f not in test_align.columns:
                test_align[f] = 0
        X_test = test_align[features]
        y_test = test_align.get(target_col)
        # 예측 확률
        probs = []
        for m in final_models:
            try:
                p = m.predict_proba(X_test)[:, 1]
            except:
                p = m.predict(X_test)
            probs.append(p)
        avg_p = np.mean(np.vstack(probs), axis=0)
        if y_test is not None:
            auc = roc_auc_score(y_test, avg_p)
            individual_metrics[f'split_{i}_auc'] = auc
            print(f"[INFO] Split {i}: Ensemble AUC = {auc:.4f}")
        test_probas.append(avg_p)

    # 전체 앙상블
    ensemble_p = np.mean(test_probas, axis=0)
    if y_test is not None:
        final_auc = roc_auc_score(y_test, ensemble_p)
        print(f"[INFO] Overall Ensemble AUC = {final_auc:.4f}")
    else:
        final_auc = None

    # 결과 구성
    result = {
        'metrics': {'cv': {'AUC': final_auc, 'individual_auc': individual_metrics}},
        'ensemble_model': f'PyCaretEnsembleSplitMajority_{n_splits}splits',
        'feature_list': features,
        'feature_importance': '',
        'subgroup_metrics': individual_metrics
    }
    pd.Series(features).to_csv(feature_path, index=False)
    print(f"[INFO] Features saved to {feature_path}")
    return result

# -----------------------------
# 실험 로깅 함수
# -----------------------------
def log_experiment(args, result_dict: dict, csv_path: str):
    metrics = result_dict.get('metrics', {})
    current_auc = None
    test_m = metrics.get('test', {})
    cv_m = metrics.get('cv', {})
    if 'roc_auc' in test_m:
        current_auc = test_m['roc_auc']
    elif 'AUC' in cv_m:
        current_auc = cv_m['AUC']
    if os.path.exists(csv_path):
        df_log = pd.read_csv(csv_path)
        last_auc = df_log.iloc[-1]['auc'] if not df_log.empty else None
    else:
        df_log = pd.DataFrame(); last_auc = None
    delta = (current_auc - last_auc) if last_auc is not None and current_auc is not None else 0
    sub_str = json.dumps(result_dict.get('subgroup_metrics', ''), ensure_ascii=False)
    entry = {
        'timestamp': datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
        'strategy': getattr(args, 'strategy', ''),
        'auc': current_auc,
        'delta': delta,
        'data_loader_strategy': args.data_loader_strategy,
        'imputation_strategy': args.imputation_strategy,
        'sampling_strategy': args.sampling_strategy,
        'labeling_strategy': args.labeling_strategy,
        'feature_engineering_strategy': args.feature_engineering_strategy,
        'modeling_strategy': args.modeling_strategy,
        'ohe_prefix': getattr(args, 'ohe_prefix', ''),
        'subgroup_col': getattr(args, 'subgroup_col', ''),
        'set_index': getattr(args, 'set_index', ''),
        'test_size': getattr(args, 'test_size', ''),
        'n_splits': getattr(args, 'n_splits', ''),
        'ensemble_model': result_dict.get('ensemble_model', ''),
        'feature_list': json.dumps(result_dict.get('feature_list', []), ensure_ascii=False),
        'all_metrics': json.dumps(metrics, ensure_ascii=False),
        'feature_importance': json.dumps(result_dict.get('feature_importance', ''), ensure_ascii=False),
        'subgroup_metrics': sub_str
    }
    df_log = pd.concat([df_log, pd.DataFrame([entry])], ignore_index=True)
    df_log.to_csv(csv_path, index=False)
    print(f"[INFO] Experiment logged to {csv_path}")

# -----------------------------
# 파이프라인 메인 함수
# -----------------------------
def main():
    parser = argparse.ArgumentParser()
    parser.add_argument('--train_file', required=True)
    parser.add_argument('--strategy', default='')
    parser.add_argument('--data_loader_strategy', default='cleaning8')
    parser.add_argument('--labeling_strategy', default='labeling6')
    parser.add_argument('--imputation_strategy', default='basic4')
    parser.add_argument('--feature_engineering_strategy', default='fe9')
    parser.add_argument('--sampling_strategy', default='sampling_dummy')
    parser.add_argument('--modeling_strategy', default='ensemble_split_majority2')
    parser.add_argument('--ohe_prefix', default='')
    parser.add_argument('--subgroup_col', default='')
    parser.add_argument('--set_index', default='')
    parser.add_argument('--test_size', type=float, default=0.1)
    parser.add_argument('--n_splits', type=int, default=3)
    parser.add_argument('--experiment_log', default='experiment_results.csv')
    parser.add_argument('--feature_importance', action='store_true')
    # PyCaret-specific args
    parser.add_argument('--model_path', default='model')
    parser.add_argument('--feature_path', default='features.csv')
    parser.add_argument('--show_feature_importance', action='store_true')
    parser.add_argument('--test_df', help='Path to test CSV for modeling', required=True)
    args = parser.parse_args()

    # 1) 데이터 로딩 & 클렌징
    df = globals()[args.data_loader_strategy](args.train_file)
    # 2) 라벨링
    df = globals()[args.labeling_strategy](df)
    # 3) 결측치 처리
    df = globals()[args.imputation_strategy](df)
    # 4) 피처 엔지니어링
    target_col = '임신 성공 여부'
    y = df[target_col]
    df, scaler, te_map = globals()[args.feature_engineering_strategy](
        df, target=y, scaler=None, return_scaler=False, is_train=True, target_enc_mapping=None
    )
    # 5) 학습/테스트 분리
    X = df.drop(columns=[target_col]); y = df[target_col]
    X_train, X_val, y_train, y_val = train_test_split(
        X, y, test_size=args.test_size, stratify=y, random_state=42
    )
    # 6) 샘플링 & Modeling
    test_df = pd.read_csv(args.test_df)
    result = globals()[args.modeling_strategy](
        X_train.assign(**{target_col: y_train}),
        X_val.assign(**{target_col: y_val}),
        model_path=args.model_path,
        feature_path=args.feature_path,
        show_feature_importance=args.show_feature_importance,
        n_splits=args.n_splits
    )
    # 7) 로깅
    log_experiment(args, result, args.experiment_log)
    # 8) 최종 피처 중요도
    if args.feature_importance and 'feature_importance' in result:
        print(result['feature_importance'])

if __name__ == '__main__':
    main()